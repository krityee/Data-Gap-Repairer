{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkrp8yZ8Pa2m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "dataset=pd.read_excel('crimes_total.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPzR8n1gPkVJ",
        "outputId": "c7ef7323-5fe3-4a6d-b029-633bf87f74f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Year', 'crimes.total'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the columns to list\n",
        "year_list=dataset[\"Year\"].tolist()\n",
        "crimes_list=dataset[\"crimes.total\"].tolist()"
      ],
      "metadata": {
        "id": "bb2VqbsDPzAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "\n",
        "import wget\n",
        "wget.download('https://raw.githubusercontent.com/BorisMuzellec/MissingDataOT/master/utils.py')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from utils import *\n",
        "import torch\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKZIBO3YQE8U",
        "outputId": "bebdb2b7-5cd2-40b3-a8a1-992ed5a36eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=ca1f09f481b7af6001fd8f5fd31ee8d9228e39b39a6f1f94d64e657a58ca3fb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "def produce_NA(X, p_miss, mecha=\"MCAR\", opt=None, p_obs=None, q=None):\n",
        "    \"\"\"\n",
        "    Generate missing values for specifics missing-data mechanism and proportion of missing values.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : torch.DoubleTensor or np.ndarray, shape (n, d)\n",
        "        Data for which missing values will be simulated.\n",
        "        If a numpy array is provided, it will be converted to a pytorch tensor.\n",
        "    p_miss : float\n",
        "        Proportion of missing values to generate for variables which will have missing values.\n",
        "    mecha : str,\n",
        "            Indicates the missing-data mechanism to be used. \"MCAR\" by default, \"MAR\", \"MNAR\" or \"MNARsmask\"\n",
        "    opt: str,\n",
        "         For mecha = \"MNAR\", it indicates how the missing-data mechanism is generated: using a logistic regression (\"logistic\"), quantile censorship (\"quantile\") or logistic regression for generating a self-masked MNAR mechanism (\"selfmasked\").\n",
        "    p_obs : float\n",
        "            If mecha = \"MAR\", or mecha = \"MNAR\" with opt = \"logistic\" or \"quanti\", proportion of variables with *no* missing values that will be used for the logistic masking model.\n",
        "    q : float\n",
        "        If mecha = \"MNAR\" and opt = \"quanti\", quantile level at which the cuts should occur.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    A dictionnary containing:\n",
        "    'X_init': the initial data matrix.\n",
        "    'X_incomp': the data with the generated missing values.\n",
        "    'mask': a matrix indexing the generated missing values.s\n",
        "    \"\"\"\n",
        "\n",
        "    to_torch = torch.is_tensor(X) ## output a pytorch tensor, or a numpy array\n",
        "    if not to_torch:\n",
        "        X = X.astype(np.float32)\n",
        "        X = torch.from_numpy(X)\n",
        "\n",
        "    if mecha == \"MAR\":\n",
        "        mask = MAR_mask(X, p_miss, p_obs).double()\n",
        "    elif mecha == \"MNAR\" and opt == \"logistic\":\n",
        "        mask = MNAR_mask_logistic(X, p_miss, p_obs).double()\n",
        "    elif mecha == \"MNAR\" and opt == \"quantile\":\n",
        "        mask = MNAR_mask_quantiles(X, p_miss, q, 1-p_obs).double()\n",
        "    elif mecha == \"MNAR\" and opt == \"selfmasked\":\n",
        "        mask = MNAR_self_mask_logistic(X, p_miss).double()\n",
        "    else:\n",
        "        mask = (torch.rand(X.shape) < p_miss).double()\n",
        "\n",
        "    X_nas = X.clone()\n",
        "    X_nas[mask.bool()] = np.nan\n",
        "\n",
        "    return {'X_init': X.double(), 'X_incomp': X_nas.double(), 'mask': mask}"
      ],
      "metadata": {
        "id": "wfoOwxmWQttD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the data is corrupted with 18% of generated missing values\n",
        "X_init=np.array(year_list)\n",
        "X_miss_mcar = produce_NA(X_init, p_miss=0.15, mecha=\"MCAR\")\n",
        "\n",
        "year_mcar = X_miss_mcar['X_incomp']\n",
        "R_mcar = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n",
        "\n",
        "print(year_mcar)\n",
        "\n",
        "year_list_15=year_mcar.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roFoHbRRQ3J5",
        "outputId": "234e6db9-a32e-4b3c-bec0-cfb3309ef69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of generated missing values:  10.606060606060606  %\n",
            "tensor([  nan, 1951., 1952., 1953., 1954., 1955., 1956.,   nan, 1958., 1959.,\n",
            "        1960., 1961., 1962., 1963., 1964., 1965., 1966.,   nan, 1968., 1969.,\n",
            "        1970., 1971., 1972., 1973., 1974., 1975., 1976., 1977., 1978., 1979.,\n",
            "          nan, 1981., 1982., 1983., 1984., 1985., 1986., 1987.,   nan, 1989.,\n",
            "        1990., 1991., 1992., 1993., 1994., 1995., 1996., 1997., 1998., 1999.,\n",
            "        2000., 2001.,   nan, 2003., 2004., 2005., 2006., 2007.,   nan, 2009.,\n",
            "        2010., 2011., 2012., 2013., 2014., 2015.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the data is corrupted with 18% of generated missing values\n",
        "X_init=np.array(crimes_list)\n",
        "X_miss_mcar = produce_NA(X_init, p_miss=0.15, mecha=\"MCAR\")\n",
        "\n",
        "crimes_mcar = X_miss_mcar['X_incomp']\n",
        "R_mcar = X_miss_mcar['mask']\n",
        "\n",
        "print(\"Percentage of generated missing values: \", (R_mcar.sum()).numpy()/np.prod(R_mcar.size())*100, \" %\")\n",
        "\n",
        "print(crimes_mcar)\n",
        "\n",
        "#the array is converted back to list\n",
        "crimes_list_15=crimes_mcar.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3bh6KULRLk7",
        "outputId": "c4db7a33-670b-41c1-de5d-16741dc927d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of generated missing values:  19.696969696969695  %\n",
            "tensor([ 2784.,  3284.,  3160.,  2909.,    nan,  3357.,  3488.,  3774.,    nan,\n",
            "         4033.,  3982.,  4108.,  4263.,  4466.,  4799.,  5801.,  6063.,  6421.,\n",
            "           nan,    nan,    nan,    nan,  8509.,  8055.,  8275.,  9221.,  9720.,\n",
            "        10233.,  9706.,  9840.,    nan, 11247., 11817., 11515., 11793., 12195.,\n",
            "           nan, 13020., 12875.,    nan,    nan, 13915.,    nan, 13664., 12670.,\n",
            "        12982., 13294., 13554., 13344.,    nan, 13694., 13370., 13663., 13997.,\n",
            "        13885., 13753., 13490., 14280.,    nan, 15101., 14605., 14988., 14734.,\n",
            "        14603., 14890., 15342.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict={\n",
        "    'year_15':year_list_15,\n",
        "    'crimes_15':crimes_list_15\n",
        "\n",
        "}\n",
        "\n",
        "crimes_data_missing_15_percent = pd.DataFrame(data_dict)\n",
        "\n",
        "#the list are merged to form a dataframe"
      ],
      "metadata": {
        "id": "KdgPYb8vRmcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the dataframe is converted to excel format\n",
        "crimes_data_missing_15_percent.to_excel('crimes_15percent_missing.xlsx', index=False)"
      ],
      "metadata": {
        "id": "ezojcelQRmp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Interpolation technique\n",
        "#First method: nearest\n",
        "dataset_15=pd.read_excel('crimes_15percent_missing.xlsx')\n",
        "\n",
        "dataset_15['year_15'].interpolate(method = 'nearest', inplace = True)\n",
        "dataset_15['crimes_15'].interpolate(method = 'nearest', inplace = True)\n",
        "\n",
        "dataset_15.to_excel('dataset_15_nearest_crime.xlsx', index=False)\n",
        "\n",
        "#second method: pad\n",
        "dataset_15=pd.read_excel('crimes_15percent_missing.xlsx')\n",
        "\n",
        "dataset_15['year_15'].interpolate(method = 'pad', inplace = True)\n",
        "dataset_15['crimes_15'].interpolate(method = 'pad', inplace = True)\n",
        "\n",
        "dataset_15.to_excel('dataset_15_pad_crime.xlsx', index=False)\n",
        "\n",
        "#third method: linear\n",
        "\n",
        "dataset_15=pd.read_excel('crimes_15percent_missing.xlsx')\n",
        "\n",
        "dataset_15['year_15'].interpolate(method = 'linear', inplace = True)\n",
        "dataset_15['crimes_15'].interpolate(method = 'linear', inplace = True)\n",
        "\n",
        "dataset_15.to_excel('dataset_15_linear_crime.xlsx', index=False)\n",
        "\n",
        "#fourth method: cubicspline\n",
        "\n",
        "dataset_15=pd.read_excel('crimes_15percent_missing.xlsx')\n",
        "\n",
        "dataset_15['ip_year_15']= dataset_15['year_15'].interpolate(method = 'cubicspline', inplace = True)\n",
        "dataset_15['ip_crimes_15']=dataset_15['crimes_15'].interpolate(method = 'cubicspline', inplace = True)\n",
        "\n",
        "dataset_15.to_excel('dataset_15_cubicspline_crime.xlsx', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "eKDhdacDRmsv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}